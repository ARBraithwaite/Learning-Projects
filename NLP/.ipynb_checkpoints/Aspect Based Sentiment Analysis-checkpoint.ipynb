{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "sys.path.append('scripts/')\n",
    "from utility import *\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") # English Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recommended</td>\n",
       "      <td>This is the game the never, ever ends. I picke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recommended</td>\n",
       "      <td>Ruined my life. Five stars.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recommended</td>\n",
       "      <td>I was stacking books on a shelf in my house in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recommended</td>\n",
       "      <td>Best game I ever bought. In this game, you'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recommended</td>\n",
       "      <td>Playing Skyrim is like masturbating. Feels goo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                             review\n",
       "0  Recommended  This is the game the never, ever ends. I picke...\n",
       "1  Recommended                        Ruined my life. Five stars.\n",
       "2  Recommended  I was stacking books on a shelf in my house in...\n",
       "3  Recommended  Best game I ever bought. In this game, you'll ...\n",
       "4  Recommended  Playing Skyrim is like masturbating. Feels goo..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/Skyrim_Reviews.csv', usecols=['review', 'rating'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opinion words\n",
    "neg_file = open(\"data/negative-words.txt\")\n",
    "pos_file = open(\"data/positive-words.txt\")\n",
    "neg = [line.strip() for line in neg_file.readlines()]\n",
    "pos = [line.strip() for line in pos_file.readlines()]\n",
    "\n",
    "opinion_words = pos + neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_sentencizer(doc):\n",
    "    \n",
    "    boundary = re.compile('\\.{2,}')\n",
    "    digits = re.compile('^[0-9]*$')\n",
    "    \n",
    "    for token in doc[:-1]:\n",
    "        if boundary.match(token.text) or digits.match(token.text) or token.text in [',', '!', '?', ':', 'and']:\n",
    "            doc[token.i+1].is_sent_start = False\n",
    "                \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(custom_sentencizer, before=\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_sentiment(text):\n",
    "    '''\n",
    "    input: dictionary and sentence\n",
    "    function: appends dictionary with new features if the feature did not exist previously,\n",
    "              then updates sentiment to each of the new or existing features\n",
    "    output: updated dictionary\n",
    "    '''\n",
    "\n",
    "    sent_dict = {}#Counter()\n",
    "    for sentence in sentence_tokenize(text):\n",
    "        sentence_tokens = nlp(sentence)\n",
    "        debug = 0\n",
    "        for token in sentence_tokens:\n",
    "            print(token)\n",
    "        #    print(token.text,token.dep_, token.head, token.head.dep_)\n",
    "            # check if the word is an opinion word, then assign sentiment\n",
    "            if token.text in opinion_words:\n",
    "                sentiment = 1 if token.text in pos else -1\n",
    "                # if target is an adverb modifier (i.e. pretty, highly, etc.)\n",
    "                # but happens to be an opinion word, ignore and pass\n",
    "                if (token.dep_ == \"advmod\"):\n",
    "                    continue\n",
    "                elif (token.dep_ == \"amod\"):\n",
    "                    sent_dict[token.head.text] += sentiment\n",
    "                # for opinion words that are adjectives, adverbs, verbs...\n",
    "                else:\n",
    "                    for child in token.children:\n",
    "                        # if there's a adj modifier (i.e. very, pretty, etc.) add more weight to sentiment\n",
    "                        # This could be better updated for modifiers that either positively or negatively emphasize\n",
    "                        if ((child.dep_ == \"amod\") or (child.dep_ == \"advmod\")) and (child.text in opinion_words):\n",
    "                            sentiment *= 1.5\n",
    "                        # check for negation words and flip the sign of sentiment\n",
    "                        if child.dep_ == \"neg\":\n",
    "                            sentiment *= -1\n",
    "                    for child in token.children:\n",
    "                        # if verb, check if there's a direct object\n",
    "                        if (token.pos_ == \"VERB\") & (child.dep_ == \"dobj\"):                        \n",
    "                            sent_dict[child.text] += sentiment\n",
    "                            # check for conjugates (a AND b), then add both to dictionary\n",
    "                            subchildren = []\n",
    "                            conj = 0\n",
    "                            for subchild in child.children:\n",
    "                                if subchild.text == \"and\":\n",
    "                                    conj=1\n",
    "                                if (conj == 1) and (subchild.text != \"and\"):\n",
    "                                    subchildren.append(subchild.text)\n",
    "                                    conj = 0\n",
    "                            for subchild in subchildren:\n",
    "                                sent_dict[subchild] += sentiment\n",
    "    \n",
    "                    # check for negation\n",
    "                    for child in token.head.children:\n",
    "                        noun = \"\"\n",
    "                        if ((child.dep_ == \"amod\") or (child.dep_ == \"advmod\")) and (child.text in opinion_words):\n",
    "                            sentiment *= 1.5\n",
    "                        # check for negation words and flip the sign of sentiment\n",
    "                        if (child.dep_ == \"neg\"): \n",
    "                            sentiment *= -1\n",
    "                    \n",
    "                    # check for nouns\n",
    "                    for child in token.head.children:\n",
    "                        noun = \"\"\n",
    "                        if (child.pos_ == \"NOUN\") and (child.text not in sent_dict):\n",
    "                            noun = child.text\n",
    "                            # Check for compound nouns\n",
    "                            for subchild in child.children:\n",
    "                                if subchild.dep_ == \"compound\":\n",
    "                                    noun = subchild.text + \" \" + noun\n",
    "                            sent_dict[noun] += sentiment\n",
    "                        debug += 1\n",
    "    return sent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got spacy.tokens.span.Span)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-fdce460f991f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"I came here with my friends on a Tuesday night. The sushi here is amazing. Our waiter was very helpful, but the music was terrible.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeature_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-0a36c403b550>\u001b[0m in \u001b[0;36mfeature_sentiment\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msent_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;31m#Counter()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0msentence_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mdebug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             )\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_format_docs_and_golds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got spacy.tokens.span.Span)"
     ]
    }
   ],
   "source": [
    "sentence= \"I came here with my friends on a Tuesday night. The sushi here is amazing. Our waiter was very helpful, but the music was terrible.\"\n",
    "feature_sentiment(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
